{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e647a4",
   "metadata": {},
   "source": [
    "# Exercise Sheet 03: Item response theory and variational autoencoders\n",
    "\n",
    "**Introduction to Data Mining WS23/24**  \n",
    "**Bielefeld University**  \n",
    "**Alina Deriyeva, Benjamin Paa√üen**  \n",
    "**Exercise Sheet Publication Date: 2023-11-20**  \n",
    "**Exercise Sheet Submission Deadline: 2023-12-01, noon (i.e. 12:00), via **moodle** (please do not use e-mail submissions anymore).\n",
    "\n",
    "**NOTE** The use of language models/AI tools is permitted IF you notify us of the use (just indicate it in the respective task) and are still able to understand and present your results. We also appreciate it if you link to a chatlog of the interaction with the language model/AI tool so that we can understand better how students tend to use these tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8967b8",
   "metadata": {},
   "source": [
    "**PLEASE INDICATE ALL AUTHORS OF THE SUBMISSION IN THIS FIELD**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2591c02c",
   "metadata": {},
   "source": [
    "## Preamble: Data set\n",
    "\n",
    "The file `sheet03_data.csv` contains fictional data of a class of students completing a set of tasks. Each row indicates a student, each column indicates a task. Each task is only graded as 'passed' (1) or 'failed' (0).\n",
    "\n",
    "The following code loads this raw data and prints it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d93f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.loadtxt('sheet03_data.csv', skiprows = 1, delimiter = '\\t', dtype=int)\n",
    "N, m = X.shape\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e93d467",
   "metadata": {},
   "source": [
    "### Task 03.01\n",
    "\n",
    "Before we apply any advanced data mining, let us compute some basic statistics to get a sense of the data.\n",
    "\n",
    "Provide a bar plot with the task index on the x axis and the pass rate on the y axis. Don't forget to label your axes.\n",
    "\n",
    "Provide a second bar plot with the student index on the x axis and the pass rate on the y axis. Don't forget to label your axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b3b0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27c9001c",
   "metadata": {},
   "source": [
    "## Item Response Theory\n",
    "\n",
    "Now, we want to fit item response theory models to our data. We will start with a 1-parameter model and then continue with a 2-parameter model.\n",
    "\n",
    "For the former, we will use the [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) interface from scikit-learn. For the latter, we will use the [girth](https://github.com/eribean/girth) software package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0a0508",
   "metadata": {},
   "source": [
    "### Task 03.02\n",
    "\n",
    "Right now, our data is in the form of an $N \\times m$ matrix, where $N$ is the number of students and $m$ is the number of tasks. To plug this data into logistic regression, we need to convert it to a different format.\n",
    "\n",
    "1. Prepare a $(N \\cdot m) \\times (N + m)$ matrix `Xlogreg` where each row represents a student-task combination. All entries are zero except for the entries `Xlogreg[i*m+j, i] = 1`, `Xlogreg[i*m+j, N+j] = 1` for all $i \\in \\{0, \\ldots, N-1\\}$ and all $j \\in \\{0, \\ldots, m\\}$. This is the feature matrix for our logistic regression.\n",
    "2. Prepare a vector `ylogreg` with $N \\cdot m$ entries where each entry represents a student-task combination and `ylogreg[i*m+j] = X[i, j]` for all $i \\in \\{0, \\ldots, N-1\\}$ and all $j \\in \\{0, \\ldots, m\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb6eba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14bd54b1",
   "metadata": {},
   "source": [
    "### Task 03.03\n",
    "\n",
    "Use the new format of the data to train an [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model with `penalty = 'l2'`, `C = 1.0`, and `fit_intercept = False`.\n",
    "\n",
    "Report the accuracy of the model by printing the output of the `score` function of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3801de1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eba1b3da",
   "metadata": {},
   "source": [
    "### Task 03.04\n",
    "\n",
    "The learned parameters of the model are stored in the `coef_` attribute. The first $N$ parameters represent the estimated student abilities, the last $m$ parameters represent the negative (!) estimated task difficulties.\n",
    "\n",
    "Extract abilities and task difficulties.\n",
    "\n",
    "Provide a scatter plot with estimated task difficulties on the x axis and pass rates on the y axis. Don't forget to label your axes.\n",
    "\n",
    "Provide a scatter plot with estimated student abilities on the x axis and pass rates on the y axis. Don't forget to label your axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b0baf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db026a96",
   "metadata": {},
   "source": [
    "### Task 03.05\n",
    "\n",
    "Plot the item characteristic curve for the second task (item index 1) according to your IRT model. To do so, sample 61 abilities via the `np.linspace` function in the range $[-3, +3]$ and plot the value of the function\n",
    "\n",
    "\\begin{equation*}\n",
    "p(x = 1|\\theta, b_2) = \\frac{1}{1 + \\exp(-(\\theta - b_2))}\n",
    "\\end{equation*}\n",
    "\n",
    "where $b_2$ is the difficulty of the second task and $\\theta$ is the ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28bf57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f955e917",
   "metadata": {},
   "source": [
    "### Task 03.06\n",
    "\n",
    "To validate the item characteristic curve, provide a plot of the pass rate of students within a certain range of abilities. In particular, compute the pass rates for students with an ability between -2.5 and -1.5, between -1.5 and -0.5, between -0.5 and +0.5, beween +0.5 and +1.5, and between +1.5 and +2.5. Then, plot these values on the y axis versus x values -2, -1, 0, +1, +2.\n",
    "\n",
    "Plot the item characteristic curve as well.\n",
    "\n",
    "Compare the pass rate curve to the item characteristic curve. Are they similar? What is different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce67acc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49e34c09",
   "metadata": {},
   "source": [
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370bebc7",
   "metadata": {},
   "source": [
    "### Task 03.07\n",
    "\n",
    "Now, use the `twopl_mml` function from the [girth](https://github.com/eribean/girth) software package to fit a 2-parameter IRT model to the data. The output of the function is a two parameter IRT model given in form of a python dictionary. You can extract the estimated difficulties via `model['Difficulty']`, the abilities via `model['Ability']`, and the discriminations via `model['Discrimination']`.\n",
    "\n",
    "**NOTE:** girth assumes that each row represents a task and each column a student. In our data format, this is flipped. So you need to transpose the data before feeding it into the `twopl_mml` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this command installs the girth software package\n",
    "%pip install girth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9c3a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from girth import twopl_mml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d007e",
   "metadata": {},
   "source": [
    "### Task 03.08\n",
    "\n",
    "Let's try to compute the accuracy of the model. To do so, we need to get the predictions of the 2-parameter model and compare them to the actual passes/fails of the students.\n",
    "\n",
    "The prediction of the model is given as\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat x_{i, j} =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } b_j < \\theta_i \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "where $b_j$ is the estimated difficulty for task $j$ and $\\theta_i$ is the estimated ability for student $i$.\n",
    "\n",
    "Compute the matrix `Xhat` of predicted pass/fails and then compute the accuracy as `np.mean(Xhat == X)`. Print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212b04c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11b330ad",
   "metadata": {},
   "source": [
    "### Task 03.09\n",
    "\n",
    "Provide a scatter plot with the estimated difficulties of the logistic regression model on the x axis and the difficulties of the 2-parameter model on the y axis. Which differences do you notice?\n",
    "\n",
    "Provide a scatter plot with the estimated abilities of the logistic regression model on the x axis and the abilities of the 2-parameter model on the y axis. Which differences do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc943e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85c65e17",
   "metadata": {},
   "source": [
    "**ANSWER:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b073cc15",
   "metadata": {},
   "source": [
    "### Task 03.10\n",
    "\n",
    "Plot the item characteristic curve of the 2-parameter model for the second task and compare it to the item characteristic curve for the logistic regression model of the second task. What differences do you notice?\n",
    "\n",
    "Recall: For a 2-parameter model, the item characteristic curve is given as\n",
    "\\begin{equation*}\n",
    "p(x = 1|\\theta, b_2, a_2) = \\frac{1}{1 + \\exp\\Big(-a_2 \\cdot (\\theta-b_2)\\Big)}\n",
    "\\end{equation*}\n",
    "where $a_2$ is the discrimination parameter for the second task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40aa419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24218296",
   "metadata": {},
   "source": [
    "**ANSWER:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f79e9",
   "metadata": {},
   "source": [
    "### Task 03.11\n",
    "\n",
    "To validate the item characteristic curve, provide a plot of the pass rate of students within a certain range of abilities. In particular, compute the pass rates for students with an ability between -2.5 and -1.5, between -1.5 and -0.5, between -0.5 and +0.5, beween +0.5 and +1.5, and between +1.5 and +2.5. Then, plot these values on the y axis versus x values -2, -1, 0, +1, +2.\n",
    "\n",
    "Plot the item characteristic curve as well.\n",
    "\n",
    "Compare the pass rate curve to the item characteristic curve. Are they similar? What is different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b513f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d4b07e5",
   "metadata": {},
   "source": [
    "**ANSWER:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ea976",
   "metadata": {},
   "source": [
    "## Variational Autoencoder\n",
    "\n",
    "Next, we will try to fit a variational autoencoder to the data. For that purpose, we will use the [pytorch](https://pytorch.org/) software package. The following line installs pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6313992",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2793e8",
   "metadata": {},
   "source": [
    "Pytorch takes care of adjusting the parameters of your model. However, you still need to specify the architecture as well as the loss function you want to optimize. The following cell provides a template for a proper pytorch model setup. In particular, this class implements a one-parameter IRT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282621df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class IRTModel(torch.nn.Module):\n",
    "    \"\"\"The initialization method of a pytorch module. Here, we should set all hyperparameters\n",
    "    of the model, such as the regularization strength.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    C: float (default = 1000)\n",
    "        The inverse of the L2 regularization strength.\n",
    "    num_epochs: int (default = 1000)\n",
    "        How many times we iterate over the data set during training.\n",
    "    learning_rate: float (default = 1E-2)\n",
    "        The learning rate of our optimizer during training.\n",
    "    \"\"\"\n",
    "    def __init__(self, C = 1000, num_epochs = 1000, learning_rate = 1E-2):\n",
    "        # We call the torch.nn.Module constructor\n",
    "        super(IRTModel, self).__init__()\n",
    "        # Then, we store all hyperparameters as attributes of the model\n",
    "        self.C_ = C\n",
    "        self.num_epochs_ = num_epochs\n",
    "        self.learning_rate_ = learning_rate\n",
    "\n",
    "    \"\"\"Predicts responses based on the learned parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: np.ndarray\n",
    "        A matrix where each row represents a student and each column represents a task.\n",
    "        The entry X[i, j] is expected to be 0 if student i failed task j and to be 1\n",
    "        if student i passed task j.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Z: torch.tensor\n",
    "        A matrix where each row represents a student and each column represents a task.\n",
    "        The entry Z[i, j] represents the logit probability of student i passing task j.\n",
    "    \n",
    "    \"\"\"\n",
    "    def predict_logits(self, X = None):\n",
    "        # the logits correspond to the difference of abilities and difficulties.\n",
    "        # The 'unsqueeze' method transforms the abilities vector from an N-entry\n",
    "        # vector to an (N, 1)-matrix and the difficulties vector from an m-entry\n",
    "        # vector to an (1, m)-matrix, such that the difference - thanks to the\n",
    "        # magic of broadcasting - yields a (N, m) matrix.\n",
    "        Z = self.abilities_.unsqueeze(1) - self.difficulties_.unsqueeze(0)\n",
    "        return Z\n",
    "\n",
    "    \"\"\"Predicts responses based on the learned parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: np.ndarray\n",
    "        A matrix where each row represents a student and each column represents a task.\n",
    "        The entry X[i, j] is expected to be 0 if student i failed task j and to be 1\n",
    "        if student i passed task j.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Xhat: np.ndarray\n",
    "        A matrix where each row represents a student and each column represents a task.\n",
    "        The entry Xhat[i, j] is 1 if the model predicts student i to pass task j and 0\n",
    "        otherwise.\n",
    "    \n",
    "    \"\"\"\n",
    "    def predict(self, X = None):\n",
    "        Z = self.predict_logits()\n",
    "        Xhat = torch.zeros_like(Z)\n",
    "        Xhat[Z > 0.] = 1.\n",
    "        return Xhat.detach().numpy()\n",
    "\n",
    "    \"\"\"Fits this model to the given data matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: np.ndarray\n",
    "        A matrix where each row represents a student and each column represents a task.\n",
    "        The entry X[i, j] is expected to be 0 if student i failed task j and to be 1\n",
    "        if student i passed task j.\n",
    "\n",
    "    \"\"\"\n",
    "    def fit(self, X):\n",
    "        # convert the input matrix to a pytorch tensor\n",
    "        X = torch.tensor(X, dtype=torch.float)\n",
    "        # initialize our model parameters based on passing rates, meaning:\n",
    "        # students have higher initial ability if they get more tasks right and\n",
    "        # items have higher initial difficulty if less students get them right.\n",
    "        self.abilities_    = torch.nn.Parameter(torch.mean(X, 1).detach() - 0.5)\n",
    "        self.difficulties_ = torch.nn.Parameter(0.5 - torch.mean(X, 0).detach())\n",
    "        # initialize optimizer with the right learning rate and regularization strength\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate_, weight_decay=1./self.C_)\n",
    "        # start training\n",
    "        for epoch in range(self.num_epochs_):\n",
    "            # re-set the current gradient to zero\n",
    "            optimizer.zero_grad()\n",
    "            # predict the logit passing probabilities for each student-item combination\n",
    "            # with the current model\n",
    "            Z = self.predict_logits()\n",
    "            # compute the loss between predicted and desired answers using the crossentropy loss\n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(Z, X)\n",
    "            # report the loss every 100 steps\n",
    "            if (epoch+1) % 100 == 0:\n",
    "                print('epoch %d: loss %g' % (epoch+1, loss.item()))\n",
    "            # compute the gradient\n",
    "            loss.backward()\n",
    "            # apply the optimizer\n",
    "            optimizer.step()\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d911f626",
   "metadata": {},
   "source": [
    "And the following cell trains this model for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00f7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pytorch = IRTModel()\n",
    "model_pytorch.fit(X)\n",
    "\n",
    "plt.plot(abilities, model_pytorch.abilities_.detach().numpy(), 'o')\n",
    "plt.xlabel('logreg IRT ability')\n",
    "plt.ylabel('pytorch IRT ability')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(difficulties, model_pytorch.difficulties_.detach().numpy(), 'o')\n",
    "plt.xlabel('logreg IRT difficulty')\n",
    "plt.ylabel('pytorch IRT difficulty')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda919e",
   "metadata": {},
   "source": [
    "### Task 03.12\n",
    "\n",
    "Starting from the template given above, set up a `torch.nn.Module` class representing a (variational) autoencoder for our data. The encoder should translate the vector of pass/fail information for one student to a two-dimensional ability vector for this student. The decoder should translate the two-dimensional abilities back to logit-probabilities of passing each task. The loss function should be the crossentropy (just as in the IRT model above) plus a loss term for the variational autoencoder.\n",
    "\n",
    "How you structure your architecture in detail is up to you. It is recommended to not go too wild, though, in order to keep training times manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75defe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class VAE_IRT_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        # We call the torch.nn.Module constructor\n",
    "        super(VAE_IRT_Model, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de73dcd1",
   "metadata": {},
   "source": [
    "### Task 03.13\n",
    "\n",
    "Fit your model to the data matrix `X`. After fitting the model, compute the accuracy of the model and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefe9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2643472d",
   "metadata": {},
   "source": [
    "### Task 03.14\n",
    "\n",
    "Compute the latent representation of each student, using the trained model.\n",
    "Provide two scatter plots (as part of the same plot), one for each latent dimension, with the pass rate of each student on the y axis and the latent representation values on the x axis.\n",
    "\n",
    "Try to interpret these plots. Do you notice any patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13955ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8668d55",
   "metadata": {},
   "source": [
    "**ANSWER:** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
