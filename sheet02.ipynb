{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e647a4",
   "metadata": {},
   "source": [
    "# Exercise Sheet 02: Principal Component Analysis, Factor Analysis, K-Means, and Gaussian Mixture Models\n",
    "\n",
    "**Introduction to Data Mining WS23/24**  \n",
    "**Bielefeld University**  \n",
    "**Alina Deriyeva, Benjamin Paa√üen**  \n",
    "**Exercise Sheet Publication Date: 2023-11-06**  \n",
    "**Exercise Sheet Submission Deadline: 2023-11-17, noon (i.e. 12:00), via **moodle** (please do not use e-mail submissions anymore).\n",
    "\n",
    "**NOTE** The use of language models/AI tools is permitted IF you notify us of the use (just indicate it in the respective task) and are still able to understand and present your results. We also appreciate it if you link to a chatlog of the interaction with the language model/AI tool so that we can understand better how students tend to use these tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8967b8",
   "metadata": {},
   "source": [
    "**PLEASE INDICATE ALL AUTHORS OF THE SUBMISSION IN THIS FIELD**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2591c02c",
   "metadata": {},
   "source": [
    "## Preamble: Data set\n",
    "\n",
    "The file `sheet02_data.csv` contains fictional data as you might find in an online course. Each row represents a student, each column a feature of the student's activity in the course, namely their number of posts in the course discussion forum, the number of questions they asked in chat during the online lectures, the number of messages they sent to their peers, and the number of points they achieved in each of the five exercises of the course.\n",
    "\n",
    "Note that there is quite a bit of missing data for later exercises because many students dropped out of the course early.\n",
    "\n",
    "The following code loads this raw data and prints it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0d93f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  1.  1. ... 56. 61. 60.]\n",
      " [ 0.  0.  0. ... nan nan nan]\n",
      " [ 7.  3.  2. ... 66. 57. nan]\n",
      " ...\n",
      " [ 0.  0.  0. ... 30. nan nan]\n",
      " [ 1.  0.  0. ... nan nan nan]\n",
      " [ 3.  0.  1. ... 40. 35. 40.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = ['num_forum_postings',\n",
    "    'num_questions',\n",
    "    'num_messages',\n",
    "    'num_completed_tasks',\n",
    "    'points_exercise_1',\n",
    "    'points_exercise_2',\n",
    "    'points_exercise_3',\n",
    "    'points_exercise_4',\n",
    "    'points_exercise_5']\n",
    "\n",
    "X = np.loadtxt('sheet02_data.csv', skiprows = 1, delimiter = '\\t')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e93d467",
   "metadata": {},
   "source": [
    "### Task 02.01\n",
    "\n",
    "Our first challenge is to impute the missing data. Fill in missing values with the mean points the respective student got on the other exercises. For students with no completed exercises, fill in zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04b3b0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I020434\\AppData\\Local\\Temp\\ipykernel_8100\\1149727745.py:2: RuntimeWarning: Mean of empty slice\n",
      "  mean_val= np.nanmean(X[:,4:], axis=1)\n"
     ]
    }
   ],
   "source": [
    "data = X.copy()\n",
    "mean_val= np.nanmean(X[:,4:], axis=1)\n",
    "mean_val=np.nan_to_num(mean_val)\n",
    "for i in range(4,9):\n",
    "    data[:,i]=np.where(np.isnan(X[:,i]),mean_val,X[:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0a0508",
   "metadata": {},
   "source": [
    "### Task 02.02\n",
    "\n",
    "Next, normalize the data by dividing by the maximum value in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cbb6eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum = [np.amax(data[:,i]) for i in range(4,9)]\n",
    "data[:,4:] = data[:,4:]/maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046940aa",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d3cbdb",
   "metadata": {},
   "source": [
    "### Task 02.03\n",
    "\n",
    "Compute the covariance matrix of the data via `np.cov` and compute the eigenvalues of the covariance matrix via `np.linalg.eigvals`. Provide a plot of the eigenvalues on the y-axis, sorted according to size (the largest eigenvalue at x=0, the second-largest on x=1, and so on).\n",
    "\n",
    "Compute and report the percentage of variance covered by the first two eigenvalues.\n",
    "\n",
    "**HINT:** `np.cov` treats the rows as variables and columns as observations. For our data set, rows are observations and columns are variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc8bb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cov_mat = np.cov(data.T)\n",
    "eigval= np.linalg.eigvals(cov_mat)\n",
    "eigval = np.sort(eigval)[::-1]\n",
    "total_var=np.sum(eigval)\n",
    "var_firsttwo_eig= (eigenvalues[:2].sum() / total_variance) * 100\n",
    "plt.plot(eigval)\n",
    "plt.xlabel('Eigenvalue index')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.title('Sorted Eigenvalues of the covvar matrix')\n",
    "plt.show()\n",
    "print('Percentage of variance covered by the first two eigenvalues:', var_firsttwo_eig, '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98eecb2",
   "metadata": {},
   "source": [
    "### Task 02.04\n",
    "\n",
    "Use the `fit` method of a `sklearn.decomposition.PCA` model to perform a principal component analysis of this data with `n_components = 2`.\n",
    "\n",
    "Transform the data to the latent space via the `transform` function of the PCA model.\n",
    "\n",
    "Plot the data using a 2D scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc00cfc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d64c4d3",
   "metadata": {},
   "source": [
    "### Task 02.05 (Bonus Task)\n",
    "\n",
    "Compute the eigenvalue decomposition of the covariance matrix and perform PCA yourself. Only retain the two components corresponding to the largest eigenvalues and plot the transformed data with a 2D scatter plot. Check whether your plot is consistent with the plot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab980d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38b34381",
   "metadata": {},
   "source": [
    "**ANSWER:** The plot is almost consistent. It is flipped because eigenvectors are invariant to sign changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf401d8",
   "metadata": {},
   "source": [
    "## Factor Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db42699",
   "metadata": {},
   "source": [
    "### Task 02.06\n",
    "\n",
    "Use the `fit` method of a `sklearn.decomposition.FactorAnalysis` model to perform a factor analysis of this data with `n_components = 2`. Use the `rotation = 'varimax'` parameter.\n",
    "\n",
    "Transform the data to the latent space via the `transform` function of the FA model.\n",
    "\n",
    "Plot the data using a 2D scatter plot.\n",
    "\n",
    "Compare this plot to the plot above. What difference do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12eb579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb0d3915",
   "metadata": {},
   "source": [
    "**ANSWER:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddcdbed",
   "metadata": {},
   "source": [
    "### Task 02.07\n",
    "\n",
    "Print the factors found by the factor analysis using `print(model.components_)`. Try to interpret both factors. What does the first factor represent? What does the second factor represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21020ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d2763e9",
   "metadata": {},
   "source": [
    "**ANSWER:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b286d18",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da442d24",
   "metadata": {},
   "source": [
    "### Task 02.07\n",
    "\n",
    "Using `sklearn.cluster.KMeans`, perform cluster analyses of the data for `n_clusters` between 2 and 10. For each value of `n_clusters`, compute the `sklearn.metrics.silhouette_score`. Provide a plot of the silhouette score on the y axis and `n_clusters` on the x axis. Report which value for `n_clusters` is best according to this analysis.\n",
    "\n",
    "**HINT:** The `silhouette_score` function requires the cluster labels as second argument. You can retrieve the cluster labels from a fitted `KMeans` model via the `predict` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604dc74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91d3b2a3",
   "metadata": {},
   "source": [
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63beff2e",
   "metadata": {},
   "source": [
    "### Task 02.08\n",
    "\n",
    "Using `sklearn.cluster.KMeans`, perform a cluster analysis of the data with `n_clusters = 2`.\n",
    "\n",
    "Get the cluster membership of each point via the `predict` function of the KMeans model.\n",
    "\n",
    "Provide a scatter plot of the latent representation of the data according to factor analysis, where the color of each point represents the cluster membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e40a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0dbe565",
   "metadata": {},
   "source": [
    "### Task 02.09 (bonus task)\n",
    "\n",
    "Repeat the cluster analysis, but perform it on the latent representation according to factor analysis. Plot the new clustering. Check if it is consistent with the plot above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e1ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20aa856f",
   "metadata": {},
   "source": [
    "**ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a206281f",
   "metadata": {},
   "source": [
    "### Task 02.10 (bonus task)\n",
    "\n",
    "Implement $K$-Means yourself. Check if your result is consistent with the result provided by the `sklearn` implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2214c90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5c22388",
   "metadata": {},
   "source": [
    "**ANSWER** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96746798",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97836104",
   "metadata": {},
   "source": [
    "### Task 02.11\n",
    "\n",
    "Using `sklearn.mixture.GaussianMixture`, perform cluster analyses of the data with `n_components` between 2 and 10. For each cluster analysis, compute the `bic` function value of the model (this is the Bayesian information criterion). Provide a plot of the bic value on the y axis with `n_components` on the x axis.\n",
    "\n",
    "Report which value for `n_components` is best according to this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa8554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5df319c",
   "metadata": {},
   "source": [
    "**ANSWER:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a6157",
   "metadata": {},
   "source": [
    "### Task 02.12\n",
    "\n",
    "Using `sklearn.mixture.GaussianMixture`, perform a cluster analysis of the data with `n_components = 2`.\n",
    "\n",
    "Get the cluster membership of each point via the `predict` function of the GaussianMixture model.\n",
    "\n",
    "Provide a scatter plot of the latent representation of the data according to factor analysis, where the color of each point represents the cluster membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b40f016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3d36096",
   "metadata": {},
   "source": [
    "### Task 02.13\n",
    "\n",
    "Using `sklearn.mixture.GaussianMixture`, perform a cluster analysis of the latent space representation according to factor analysis with `n_components = 3`.\n",
    "\n",
    "Get the cluster membership of each point via the `predict` function of the GaussianMixture model.\n",
    "\n",
    "Provide a scatter plot, where the color of each point represents the cluster membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52229929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce20f6b2",
   "metadata": {},
   "source": [
    "### Task 02.14\n",
    "\n",
    "Print the mean feature values for each cluster. Try to interpret the clusters: What characterizes the differenct clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16bd57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa3ae774",
   "metadata": {},
   "source": [
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba116529",
   "metadata": {},
   "source": [
    "### Task 02.15\n",
    "\n",
    "Recall the equation for the expected negative log likelihood in a Gaussian mixture model from the lecture:\n",
    "\n",
    "\\begin{align*}\n",
    "Q = &\\sum_{i=1}^N \\sum_{k=1}^K -\\gamma_{k,i} \\cdot \\log\\Big[ p_{X|Z}(x_i|k) \\cdot p_Z(k) \\Big]\\\\\n",
    "=& \\sum_{i=1}^N \\sum_{k=1}^K \\gamma_{k,i} \\cdot \\Big(\\frac{1}{2}\\log[2\\pi \\det(\\Sigma_k)] + \\frac{1}{2} (x_i - \\mu_k)^T \\Sigma_k^{-1} (x_i - \\mu_k) - \\log[p_Z(k)]\\Big)\n",
    "\\end{align*}\n",
    "\n",
    "Assuming that $Q$ is convex, find the optimal values for $\\mu_k$ and $\\Sigma_k$\n",
    "\n",
    "**HINT:** You may use the following general matrix/vector gradient equations (refer to the [matrix cook book by Peterson and Pedersen (2012), p.10-11](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf) :\n",
    "\\begin{align*}\n",
    "\\nabla_x (x - y)^T W (x - y) &= 2 W (x-y) \\\\\n",
    "\\nabla_W (x - y)^T W (x - y) &= (x-y)(x-y)^T \\\\\n",
    "\\nabla_{W^{-1}} \\log[\\det(W)] &= -W & \\text{if $W$ is symmetric and positive semi-definite}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a423cd15",
   "metadata": {},
   "source": [
    "**ANSWER:**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
